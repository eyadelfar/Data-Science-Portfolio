{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bde4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eyad\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle as pk\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier ,ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score ,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c01b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Train.csv')\n",
    "# df_train = pd.read_parquet('pre_train.parquet').iloc[:,1:]\n",
    "df_val = pd.read_csv('Valid.csv')\n",
    "df_test = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bda0b149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Harrison Ford playing a playing a cop in a crime thriller. The perfect ingredients it SEEMS for top entertainment with Harrison back to his Indy and Han Solo best, protecting a witness from ruthless and merciless murderers. How easy it is to be fooled. If the film concentrated on the main, supposed, themes of crime and suspense instead of putting up barns and shoving ice creams in peoples faces it possibly could have been more worthwhile. Unbelieveably predictable with the best method of despatching of a foe is with corn.'],\n",
       "       [1]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((df_val.sample(1).text , df_val.sample(1).label) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a4ce584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697583bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's been about 14 years since Sharon Stone aw...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>someone needed to make a car payment... this i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  It's been about 14 years since Sharon Stone aw...      0\n",
       "1  someone needed to make a car payment... this i...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25e59b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>39723</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Hilarious, clean, light-hearted, and quote-wor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.499525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text         label\n",
       "count                                               40000  40000.000000\n",
       "unique                                              39723           NaN\n",
       "top     Hilarious, clean, light-hearted, and quote-wor...           NaN\n",
       "freq                                                    4           NaN\n",
       "mean                                                  NaN      0.499525\n",
       "std                                                   NaN      0.500006\n",
       "min                                                   NaN      0.000000\n",
       "25%                                                   NaN      0.000000\n",
       "50%                                                   NaN      0.000000\n",
       "75%                                                   NaN      1.000000\n",
       "max                                                   NaN      1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include= \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f964856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text_length'] = df_train['text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d98187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(df_train[df_train.text_length > 5500].index , axis = 0 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f53b4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(inplace=True)\n",
    "# print(df_train.shape)\n",
    "# df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f36d428",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec4e68cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing\n",
    "df_train['text'] = df_train['text'].str.lower()\n",
    "# Tokenization and removal of punctuation\n",
    "df_train['text'] = df_train['text'].apply(lambda x: word_tokenize(x.translate(str.maketrans('', '', string.punctuation))))\n",
    "\n",
    "# Removal of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_train['text'] = df_train['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_train['text'] = df_train['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Joining the tokens back to text\n",
    "df_train['text'] = df_train['text'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02bd7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc752fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac = 1)\n",
    "df_train.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d944e916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30871</td>\n",
       "      <td>80 best time worst time james karin starred on...</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28297</td>\n",
       "      <td>good movie keep front tv dying see resultbr br...</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text  label  \\\n",
       "0  30871  80 best time worst time james karin starred on...      0   \n",
       "1  28297  good movie keep front tv dying see resultbr br...      0   \n",
       "\n",
       "   text_length  \n",
       "0          952  \n",
       "1          273  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965ceb9",
   "metadata": {},
   "source": [
    "## Tokenizing for Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73a2de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=2500)\n",
    "tokenizer.fit_on_texts(df_train['text'])\n",
    "train_sequences = tokenizer.texts_to_sequences(df_train['text'])\n",
    "val_sequences = tokenizer.texts_to_sequences(df_val['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b8275f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to the same length\n",
    "max_length = 256\n",
    "train_data = pad_sequences(train_sequences, maxlen=max_length)\n",
    "val_data = pad_sequences(val_sequences, maxlen=max_length)\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e03c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "622/622 [==============================] - 383s 608ms/step - loss: 0.3572 - accuracy: 0.8452 - val_loss: 0.3194 - val_accuracy: 0.8642\n",
      "Epoch 2/10\n",
      "622/622 [==============================] - 381s 612ms/step - loss: 0.2829 - accuracy: 0.8815 - val_loss: 0.3092 - val_accuracy: 0.8712\n",
      "Epoch 3/10\n",
      "622/622 [==============================] - 425s 684ms/step - loss: 0.2568 - accuracy: 0.8938 - val_loss: 0.3159 - val_accuracy: 0.8716\n",
      "Epoch 4/10\n",
      "622/622 [==============================] - 418s 672ms/step - loss: 0.2345 - accuracy: 0.9054 - val_loss: 0.3182 - val_accuracy: 0.8734\n",
      "Epoch 5/10\n",
      "622/622 [==============================] - 438s 704ms/step - loss: 0.2194 - accuracy: 0.9106 - val_loss: 0.3234 - val_accuracy: 0.8702\n",
      "Epoch 6/10\n",
      "622/622 [==============================] - 470s 755ms/step - loss: 0.1995 - accuracy: 0.9196 - val_loss: 0.3339 - val_accuracy: 0.8694\n",
      "Epoch 7/10\n",
      "622/622 [==============================] - 448s 721ms/step - loss: 0.1798 - accuracy: 0.9295 - val_loss: 0.3530 - val_accuracy: 0.8662\n",
      "Epoch 8/10\n",
      "622/622 [==============================] - 474s 762ms/step - loss: 0.1641 - accuracy: 0.9356 - val_loss: 0.3616 - val_accuracy: 0.8562\n",
      "Epoch 9/10\n",
      "622/622 [==============================] - 474s 762ms/step - loss: 0.1534 - accuracy: 0.9412 - val_loss: 0.3927 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "622/622 [==============================] - 473s 761ms/step - loss: 0.1252 - accuracy: 0.9542 - val_loss: 0.4132 - val_accuracy: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb8c7cf340>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(2500, 256, input_length=max_length))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(16))  \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, df_train['label'], validation_data = (val_data, df_val['label']), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e35b252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 35s 211ms/step\n",
      "F1 Score :  0.8609141484104577\n",
      "confusion matrix: \n",
      " [[2083  403]\n",
      " [ 292 2222]]\n",
      "Accuracy: 0.861\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.predict(val_data)\n",
    "predictions = np.round(predictions).flatten()\n",
    "print('F1 Score : ',f1_score(df_val['label'], predictions, average='weighted'))\n",
    "print('confusion matrix: \\n' , confusion_matrix(df_val['label'],predictions))\n",
    "print(\"Accuracy:\", accuracy_score(df_val['label'], predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d9374",
   "metadata": {},
   "source": [
    "## VECTORIZE & Machine Leaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a290660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train['text']\n",
    "y = np.array(df_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a0b35b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80 best time worst time james karin starred on...\n",
       "1    good movie keep front tv dying see resultbr br...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10cd5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=12500 , ngram_range=(1,2))\n",
    "train_x = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "194225f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = vect.transform(df_val['text'])\n",
    "test_x = vect.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e1ebdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorizer for deployment\n",
    "#pk.dump(vect , open('vectortizer.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ee85bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_x.toarray()\n",
    "X_val = val_x.toarray()\n",
    "X_test = test_x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c7c40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.astype('int')\n",
    "y_val = df_val['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54808b",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf28b4db",
   "metadata": {},
   "source": [
    "#### RandomForest MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d3299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_model = RandomForestClassifier(n_estimators=250,max_depth = 24, min_samples_split=25, n_jobs=-1, verbose= 2)\n",
    "# RF_model.fit(X_train,y_train)\n",
    "# rf_y_pred = RF_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train score: ' ,RF_model.score(X_train, y_train))\n",
    "# print('test score: ' ,RF_model.score(val_x, y_val))\n",
    "# print('accuracy score: ' ,accuracy_score(rf_y_pred, y_val))\n",
    "# print('F1 Score : ',f1_score(y_val, rf_y_pred, average='weighted'))\n",
    "# print('confusion matrix: \\n' , confusion_matrix(y_val,rf_y_pred))\n",
    "\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "\n",
    "# train score:  0.8699657463151339\n",
    "# test score:  0.7294\n",
    "# accuracy score:  0.7294\n",
    "# F1 Score :  0.7117945023461818\n",
    "# confusion matrix: \n",
    "#  [[1199 1287]\n",
    "#  [  66 2448]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73205ad",
   "metadata": {},
   "source": [
    "#### LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dcae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression(n_jobs=-1) \n",
    "LR_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_y_pred = LR_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train score: ' ,LR_model.score(X_train, y_train))\n",
    "print('test score: ' ,LR_model.score(val_x, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debd72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy score: ' ,accuracy_score(lr2_y_pred, np.array(y_val)))\n",
    "print('F1 Score : ',f1_score(np.array(y_val), lr2_y_pred, average='weighted'))\n",
    "print('confusion matrix: \\n' , confusion_matrix(np.array(y_val),lr2_y_pred))\n",
    "# accuracy score:  0.8812\n",
    "# F1 Score :  0.8808737409797148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13763afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8adec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model\n",
    "\n",
    "# pk.dump(LR_model , open('LR_Model88.sav','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c209e1",
   "metadata": {},
   "source": [
    "#### XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d133ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = XGBClassifier(n_estimators=200, max_depth=10 , eta=0.6, subsample=0.7, colsample_bytree=0.7,n_jobs=-1 ,verbosity =3)\n",
    "XGB_model.fit(X_train,y_train)\n",
    "xg_y_pred = XGB_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc24f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy score: ' ,accuracy_score(xg_y_pred, y_val))\n",
    "print('F1 Score : ',f1_score(y_val, xg_y_pred, average='weighted'))\n",
    "print('confusion matrix: \\n' , confusion_matrix(y_val,xg_y_pred))\n",
    "\n",
    "# ---------------------------\n",
    "# ---------------------------\n",
    "\n",
    "# accuracy score:  0.848\n",
    "# F1 Score :  0.8475825642164702\n",
    "# confusion matrix: \n",
    "#  [[1982  504]\n",
    "#  [ 256 2258]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8b0e6",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8eb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors= 100,n_jobs=-1)\n",
    "knn_model.fit(X_train,y_train)\n",
    "knn_y_pred = knn_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94638db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy score: ' ,accuracy_score(knn_y_pred, y_val))\n",
    "print('F1 Score : ',f1_score(y_val, knn_y_pred, average='weighted'))\n",
    "print('confusion matrix: \\n' , confusion_matrix(y_val,knn_y_pred))\n",
    "\n",
    "# --------------------\n",
    "# --------------------\n",
    "\n",
    "# accuracy score:  0.6982\n",
    "# F1 Score :  0.6950688294693479\n",
    "# confusion matrix: \n",
    "#  [[1992  494]\n",
    "#  [1015 1499]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f89c3",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0f59cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "etc_model = ExtraTreesClassifier(n_estimators=250,max_depth = 12, min_samples_split=50, n_jobs=-1, verbose= 2)\n",
    "etc_model.fit(X_train,y_train)\n",
    "etc_y_pred = etc_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fdcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train score: ' ,etc_model.score(X_train, y_train))\n",
    "print('test score: ' ,etc_model.score(val_x, y_val))\n",
    "print('accuracy score: ' ,accuracy_score(etc_y_pred, y_val))\n",
    "print('F1 Score : ',f1_score(y_val, etc_y_pred, average='weighted'))\n",
    "print('confusion matrix: \\n' , confusion_matrix(y_val,etc_y_pred))\n",
    "\n",
    "# ------------------\n",
    "# ------------------\n",
    "\n",
    "# train score:  0.8871963877932323\n",
    "# test score:  0.7446\n",
    "# accuracy score:  0.7446\n",
    "# F1 Score :  0.729544218437901\n",
    "# confusion matrix: \n",
    "#  [[1265 1221]\n",
    "#  [  56 2458]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ae8d68",
   "metadata": {},
   "source": [
    "#### Multinomial Bayes naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cff3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model = MultinomialNB(alpha=16)\n",
    "NB_model.fit(X_train,y_train)\n",
    "nb_y_pred = NB_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train score: ' ,NB_model.score(X_train, y_train))\n",
    "print('test score: ' ,NB_model.score(val_x, y_val))\n",
    "print('accuracy score: ' ,accuracy_score(nb_y_pred, y_val))\n",
    "print('F1 Score : ',f1_score(y_val, nb_y_pred, average='weighted'))\n",
    "print('confusion matrix: \\n' , confusion_matrix(y_val,nb_y_pred))\n",
    "\n",
    "# ------------------\n",
    "# ------------------\n",
    "\n",
    "# train score:  0.8775520479319286\n",
    "# test score:  0.8662\n",
    "# accuracy score:  0.8662\n",
    "# F1 Score :  0.8661798021138692\n",
    "# confusion matrix: \n",
    "#  [[2127  359]\n",
    "#  [ 310 2204]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2d88c5",
   "metadata": {},
   "source": [
    "### Trying to see ensembling score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d887cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f54ba0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Predictions Accuracy: 0.8816\n",
      "F1 Score :  0.8812945027987608\n"
     ]
    }
   ],
   "source": [
    "combined_predictions = np.round((prd + lr2_y_pred + nb_y_pred) / 3)\n",
    "print(\"Combined Predictions Accuracy:\", accuracy_score(y_val, combined_predictions))\n",
    "print('F1 Score : ',f1_score(y_val, combined_predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77e8f6",
   "metadata": {},
   "source": [
    "### Save  model , submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73ae4770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 36s 227ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict(test_data)\n",
    "y_test = np.round(y_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd332099",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t1 = y_test.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "170683df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t2  = NB_model.predict(X_test)\n",
    "y_t3  = LR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t4 = knn_model.predict(X_test)\n",
    "y_t5 = XGB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "521ff437",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_predictions = np.round((y_t1 +y_t2 + y_t3 + y_t4 + y_t5) /5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8ba0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = combined_predictions.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4579847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = LR_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83dc9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5ccef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub.label = cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d318097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub_DL2.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a6d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
